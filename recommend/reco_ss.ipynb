{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "from logistic_regression import *\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from cage import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from losses import *\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.set_printoptions(threshold=20)\n",
    "\n",
    "objs = []\n",
    "\n",
    "with open('Data/rec/d_processed.p', 'rb') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            o = pickle.load(f)\n",
    "        except EOFError:\n",
    "            break\n",
    "        objs.append(o)\n",
    "\n",
    "x_supervised = torch.tensor(objs[0]).double()\n",
    "y_supervised = torch.tensor(objs[3]).long()\n",
    "l_supervised = torch.tensor(objs[2]).long()\n",
    "s_supervised = torch.tensor(objs[2]).double()\n",
    "\n",
    "objs = []\n",
    "with open('Data/rec/U_processed.p', 'rb') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            o = pickle.load(f)\n",
    "        except EOFError:\n",
    "            break\n",
    "        objs.append(o)\n",
    "\n",
    "x_unsupervised = torch.tensor(objs[0]).double()\n",
    "y_unsupervised = torch.tensor(objs[3]).long()\n",
    "l_unsupervised = torch.tensor(objs[2]).long()\n",
    "s_unsupervised = torch.tensor(objs[2]).double()\n",
    "\n",
    "objs = []\n",
    "with open('Data/rec/validation_processed.p', 'rb') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            o = pickle.load(f)\n",
    "        except EOFError:\n",
    "            break\n",
    "        objs.append(o)\n",
    "\n",
    "x_valid = torch.tensor(objs[0]).double()[:100]\n",
    "y_valid = objs[3][:100]\n",
    "l_valid = torch.tensor(objs[2]).long()[:100]\n",
    "s_valid = torch.tensor(objs[2])[:100]\n",
    "\n",
    "objs1 = []\n",
    "with open('Data/rec/test_processed.p', 'rb') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            o = pickle.load(f)\n",
    "        except EOFError:\n",
    "            break\n",
    "        objs1.append(o)\n",
    "x_test = torch.tensor(objs1[0]).double()\n",
    "y_test = objs1[3]\n",
    "l_test = torch.tensor(objs1[2]).long()\n",
    "s_test = torch.tensor(objs1[2]).double()\n",
    "\n",
    "n_classes = 2\n",
    "n_lfs = 5\n",
    "n_features = x_supervised.shape[1]\n",
    "\n",
    "# Labeling Function Classes\n",
    "k = torch.from_numpy(np.array([1, 1, 1, 1, 0])).long()\n",
    "\n",
    "continuous_mask = torch.zeros(n_lfs).double()\n",
    "\n",
    "a = torch.ones(n_lfs).double() * 0.9\n",
    "\n",
    "# a = torch.tensor(np.load(\"Data/rec/prec.npy\")).double()\n",
    "\n",
    "for i in range(s_supervised.shape[0]):\n",
    "    for j in range(s_supervised.shape[1]):\n",
    "        if s_supervised[i, j].item() > 0.999:\n",
    "            s_supervised[i, j] = 0.999\n",
    "        if s_supervised[i, j].item() < 0.001:\n",
    "            s_supervised[i, j] = 0.001\n",
    "\n",
    "for i in range(s_unsupervised.shape[0]):\n",
    "    for j in range(s_unsupervised.shape[1]):\n",
    "        if s_unsupervised[i, j].item() > 0.999:\n",
    "            s_unsupervised[i, j] = 0.999\n",
    "        if s_unsupervised[i, j].item() < 0.001:\n",
    "            s_unsupervised[i, j] = 0.001\n",
    "\n",
    "for i in range(s_valid.shape[0]):\n",
    "    for j in range(s_valid.shape[1]):\n",
    "        if s_valid[i, j].item() > 0.999:\n",
    "            s_valid[i, j] = 0.999\n",
    "        if s_valid[i, j].item() < 0.001:\n",
    "            s_valid[i, j] = 0.001\n",
    "\n",
    "for i in range(s_test.shape[0]):\n",
    "    for j in range(s_test.shape[1]):\n",
    "        if s_test[i, j].item() > 0.999:\n",
    "            s_test[i, j] = 0.999\n",
    "        if s_test[i, j].item() < 0.001:\n",
    "            s_test[i, j] = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([37679, 67369]))\n"
     ]
    }
   ],
   "source": [
    "l = torch.cat([l_supervised, l_unsupervised])\n",
    "s = torch.cat([s_supervised, s_unsupervised])\n",
    "x_train = torch.cat([x_supervised, x_unsupervised])\n",
    "y_train = torch.cat([y_supervised, y_unsupervised])\n",
    "supervised_mask = torch.cat([torch.ones(l_supervised.shape[0]), torch.zeros(l_unsupervised.shape[0])])\n",
    "print(np.unique(y_unsupervised.numpy(), return_counts=True))\n",
    "\n",
    "pi = torch.ones((n_classes, n_lfs)).double()\n",
    "pi.requires_grad = True\n",
    "\n",
    "theta = torch.ones((n_classes, n_lfs)).double() * 1\n",
    "theta.requires_grad = True\n",
    "\n",
    "pi_y = torch.ones(n_classes).double()\n",
    "pi_y.requires_grad = True\n",
    "\n",
    "lr_model = LogisticRegression(n_features, n_classes)\n",
    "\n",
    "optimizer = torch.optim.Adam([{\"params\": lr_model.parameters()}, {\"params\": [pi, pi_y, theta]}], lr=0.001)\n",
    "optimizer_lr = torch.optim.Adam(lr_model.parameters(), lr=0.0003)\n",
    "optimizer_gm = torch.optim.Adam([theta, pi, pi_y], lr=0.01, weight_decay=0)\n",
    "# optimizer = torch.optim.Adam([theta, pi, pi_y], lr=0.01, weight_decay=0)\n",
    "supervised_criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([112971, 200]),\n",
       " torch.Size([112971]),\n",
       " torch.Size([112971, 5]),\n",
       " torch.Size([112971, 5]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, l.shape, s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x_train, y_train, l, s, supervised_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "best_score = 0\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\taccuracy_score: 0.36006104719417703\n",
      "Epoch: 0\taccuracy_score: 0.36006104719417703\n",
      "Epoch: 0\taccuracy_score(Valid): 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/ipykernel_launcher.py:71: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/rec/run 5/rec_gm_13456p.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-56fc1f0765fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 }\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models/rec/run {}/rec_gm_{}.pt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models/rec/run {}/rec_lr_{}.pt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {}\\taccuracy_score(Valid): {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/poincare/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/poincare/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/poincare/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/rec/run 5/rec_gm_13456p.pt'"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    lr_model.train()\n",
    "    # optimizer_lr.zero_grad()\n",
    "    # optimizer_gm.zero_grad()\n",
    "    #\n",
    "    # loss_1 = supervised_criterion(lr_model(x_supervised), y_supervised)\n",
    "    # loss_4 = log_likelihood_loss_supervised(theta, pi_y, pi, y_supervised, l_supervised, s_supervised, k, n_classes,\n",
    "    #                                         continuous_mask)\n",
    "    #\n",
    "    # probs_graphical = probability(theta, pi_y, pi, l_supervised, s_supervised, k, n_classes, continuous_mask)\n",
    "    # probs_graphical = (probs_graphical.T / probs_graphical.sum(1)).T\n",
    "    # probs_lr = torch.nn.Softmax()(lr_model(x_supervised))\n",
    "    # # loss_6 = kl_divergence(probs_graphical, probs_lr)\n",
    "    #\n",
    "    # loss_6 = - torch.log(1 - probs_graphical*(1 - probs_lr)).sum(1).mean()\n",
    "    # loss = loss_1 + loss_4 + loss_6 #+ prec_loss\n",
    "    #\n",
    "    # # print(loss)\n",
    "    # loss.backward()\n",
    "    # optimizer_gm.step()\n",
    "    # optimizer_lr.step()\n",
    "    # print(theta.grad)\n",
    "    # input()\n",
    "\n",
    "    for batch_ndx, sample in enumerate(loader):\n",
    "        optimizer_lr.zero_grad()\n",
    "        optimizer_gm.zero_grad()\n",
    "        supervised_indices = sample[4].nonzero().view(-1)\n",
    "        unsupervised_indices = (1-sample[4]).nonzero().squeeze()\n",
    "\n",
    "        if len(supervised_indices) > 0:\n",
    "            loss_1 = supervised_criterion(lr_model(sample[0][supervised_indices]), sample[1][supervised_indices])\n",
    "        else:\n",
    "            loss_1 = 0\n",
    "\n",
    "        unsupervised_lr_probability = torch.nn.Softmax()(lr_model(sample[0][unsupervised_indices]))\n",
    "        loss_2 = entropy(unsupervised_lr_probability)\n",
    "\n",
    "        y_pred_unsupervised = np.argmax(\n",
    "            probability(theta, pi_y, pi, sample[2][unsupervised_indices], sample[3][unsupervised_indices], k, n_classes,\n",
    "                        continuous_mask).detach().numpy(), 1)\n",
    "        loss_3 = supervised_criterion(lr_model(sample[0][unsupervised_indices]), torch.tensor(y_pred_unsupervised))\n",
    "\n",
    "        if len(supervised_indices) > 0:\n",
    "            loss_4 = log_likelihood_loss_supervised(theta, pi_y, pi, sample[1][supervised_indices], sample[2][supervised_indices], sample[3][supervised_indices], k, n_classes,\n",
    "                                                    continuous_mask)\n",
    "        else:\n",
    "            loss_4 = 0\n",
    "\n",
    "        loss_5 = log_likelihood_loss(theta, pi_y, pi, sample[2][unsupervised_indices], sample[3][unsupervised_indices], k, n_classes, continuous_mask)\n",
    "\n",
    "        prec_loss = precision_loss(theta, k, n_classes, a)\n",
    "\n",
    "        # loss = loss_1 #+ loss_2 + loss_3 + loss_4 + loss_5 + loss_6 + prec_loss\n",
    "        # loss = loss_4 + loss_5 + prec_loss\n",
    "\n",
    "        probs_graphical = probability(theta, pi_y, pi, sample[2], sample[3], k, n_classes, continuous_mask)\n",
    "        probs_graphical = (probs_graphical.T / probs_graphical.sum(1)).T\n",
    "        probs_lr = torch.nn.Softmax()(lr_model(sample[0]))\n",
    "        loss_6 = kl_divergence(probs_graphical, probs_lr)\n",
    "        # loss_6 = - torch.log(1 - probs_graphical * (1 - probs_lr)).sum(1).mean()\n",
    "\n",
    "        loss = loss_1 + loss_4 + loss_3 + loss_5 + prec_loss+ loss_6# + prec_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_gm.step()\n",
    "        optimizer_lr.step()\n",
    "    y_pred = np.argmax(probability(theta, pi_y, pi, l_test, s_test, k, n_classes, continuous_mask).detach().numpy(), 1)\n",
    "    print(\"Epoch: {}\\taccuracy_score: {}\".format(epoch, accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    probs = torch.nn.Softmax()(lr_model(x_test))\n",
    "    y_pred = np.argmax(probs.detach().numpy(), 1)\n",
    "    print(\"Epoch: {}\\taccuracy_score: {}\".format(epoch, accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    y_pred = np.argmax(probability(theta, pi_y, pi, l_valid, s_valid, k, n_classes, continuous_mask).detach().numpy(), 1)\n",
    "    print(\"Epoch: {}\\taccuracy_score(Valid): {}\".format(epoch, accuracy_score(y_valid, y_pred)))\n",
    "\n",
    "    probs = torch.nn.Softmax()(lr_model(x_valid))\n",
    "    y_pred = np.argmax(probs.detach().numpy(), 1)\n",
    "\n",
    "    score = accuracy_score(y_valid, y_pred)\n",
    "    if score > best_score:\n",
    "        best_epoch = epoch\n",
    "        best_score = score\n",
    "        loss_type = \"13456p\"\n",
    "        run = 5\n",
    "        checkpoint = {\n",
    "                    'theta': theta,\n",
    "                    'pi': pi,\n",
    "                }\n",
    "\n",
    "        torch.save(checkpoint, \"models/rec/run {}/rec_gm_{}.pt\".format(run, loss_type))\n",
    "        torch.save(lr_model.state_dict(), \"models/rec/run {}/rec_lr_{}.pt\".format(run, loss_type))\n",
    "    print(\"Epoch: {}\\taccuracy_score(Valid): {}\".format(epoch, accuracy_score(y_valid, y_pred)))\n",
    "\n",
    "print(best_epoch, best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
