{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ayusham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0831 00:06:31.718183 139997562042176 utils_rec.py:213] Downloading raw data\n",
      "I0831 00:06:31.719222 139997562042176 utils_rec.py:217] Processing book data\n",
      "I0831 00:06:47.393038 139997562042176 utils_rec.py:219] Processing interaction data\n",
      "/home/ayusham/Semi_Supervised_LFs/utils_rec.py:223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_interactions_nz[\"rating_4_5\"] = df_interactions_nz.rating.map(ratings_map)\n",
      "I0831 00:08:44.506204 139997562042176 utils_rec.py:224] Processing review data\n",
      "I0831 00:09:28.239889 139997562042176 utils_rec.py:226] Joining interaction data\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"recsys\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Loading Data\n",
    "\n",
    "# %% [markdown]\n",
    "# We start by running the `download_and_process_data` function.\n",
    "# The function returns the `df_train`, `df_test`, `df_dev`, `df_valid` dataframes, which correspond to our training, test, development, and validation sets.\n",
    "# Each of those dataframes has the following fields:\n",
    "# * `user_idx`: A unique identifier for a user.\n",
    "# * `book_idx`: A unique identifier for a book that is being rated by the user.\n",
    "# * `book_idxs`: The set of books that the user has interacted with (read or planned to read).\n",
    "# * `review_text`: Optional text review written by the user for the book.\n",
    "# * `rating`: Either `0` (which means the user did not read or did not like the book) or `1` (which means the user read and liked the book). The `rating` field is missing for `df_train`.\n",
    "# Our objective is to predict whether a given user (represented by the set of book_idxs the user has interacted with) will read and like any given book.\n",
    "# That is, we want to train a model that takes a set of `book_idxs` (the user) and a single `book_idx` (the book to rate) and predicts the `rating`.\n",
    "#\n",
    "# In addition, `download_and_process_data` also returns the `df_books` dataframe, which contains one row per book, along with metadata for that book (such as `title` and `first_author`).\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "from utils_rec import download_and_process_data\n",
    "\n",
    "(df_train, df_test, df_dev, df_valid), df_books = download_and_process_data()\n",
    "\n",
    "df_books.head()\n",
    "\n",
    "# %% [markdown]\n",
    "# We look at a sample of the labeled development set.\n",
    "# As an example, we want our final recommendations model to be able to predict that a user who has interacted with `book_idxs` (25743, 22318, 7662, 6857, 83, 14495, 30664, ...) would either not read or not like the book with `book_idx` 22764 (first row), while a user who has interacted with `book_idxs` (3880, 18078, 9092, 29933, 1511, 8560, ...) would read and like the book with `book_idx` 3181 (second row).\n",
    "\n",
    "# %%\n",
    "df_dev.sample(frac=1, random_state=12).head()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Writing Labeling Functions\n",
    "\n",
    "# %%\n",
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1\n",
    "\n",
    "# %% [markdown]\n",
    "# If a user has interacted with several books written by an author, there is a good chance that the user will read and like other books by the same author.\n",
    "# We express this as a labeling function, using the `first_author` field in the `df_books` dataframe.\n",
    "# We picked the threshold 15 by plotting histograms and running error analysis using the dev set.\n",
    "\n",
    "# %%\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "\n",
    "book_to_first_author = dict(zip(df_books.book_idx, df_books.first_author))\n",
    "first_author_to_books_df = df_books.groupby(\"first_author\")[[\"book_idx\"]].agg(set)\n",
    "first_author_to_books = dict(\n",
    "    zip(first_author_to_books_df.index, first_author_to_books_df.book_idx)\n",
    ")\n",
    "\n",
    "\n",
    "@labeling_function(\n",
    "    resources=dict(\n",
    "        book_to_first_author=book_to_first_author,\n",
    "        first_author_to_books=first_author_to_books,\n",
    "    )\n",
    ")\n",
    "def shared_first_author(x, book_to_first_author, first_author_to_books):\n",
    "    author = book_to_first_author[x.book_idx]\n",
    "    same_author_books = first_author_to_books[author]\n",
    "    num_read = len(set(x.book_idxs).intersection(same_author_books))\n",
    "    return POSITIVE if num_read > 15 else ABSTAIN\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# We can also leverage the long text reviews written by users to guess whether they liked or disliked a book.\n",
    "# For example, the third `df_dev` entry above has a review with the text `'4.5 STARS'`, which indicates that the user liked the book.\n",
    "# We write a simple LF that looks for similar phrases to guess the user's rating of a book.\n",
    "# We interpret >= 4 stars to indicate a positive rating, while < 4 stars is negative.\n",
    "\n",
    "# %%\n",
    "low_rating_strs = [\n",
    "    \"one star\",\n",
    "    \"1 star\",\n",
    "    \"two star\",\n",
    "    \"2 star\",\n",
    "    \"3 star\",\n",
    "    \"three star\",\n",
    "    \"3.5 star\",\n",
    "    \"2.5 star\",\n",
    "    \"1 out of 5\",\n",
    "    \"2 out of 5\",\n",
    "    \"3 out of 5\",\n",
    "]\n",
    "high_rating_strs = [\"5 stars\", \"five stars\", \"four stars\", \"4 stars\", \"4.5 stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 795517/795517 [12:53<00:00, 1028.70it/s]\n",
      "100%|██████████| 9193/9193 [00:08<00:00, 1063.28it/s]\n",
      "100%|██████████| 8989/8989 [00:08<00:00, 1047.90it/s]\n",
      "100%|██████████| 42028/42028 [00:41<00:00, 1023.39it/s]\n"
     ]
    }
   ],
   "source": [
    "@labeling_function(\n",
    "    resources=dict(low_rating_strs=low_rating_strs, high_rating_strs=high_rating_strs)\n",
    ")\n",
    "def stars_in_review(x, low_rating_strs, high_rating_strs):\n",
    "    if not isinstance(x.review_text, str):\n",
    "        return ABSTAIN\n",
    "    for low_rating_str in low_rating_strs:\n",
    "        if low_rating_str in x.review_text.lower():\n",
    "            return NEGATIVE\n",
    "    for high_rating_str in high_rating_strs:\n",
    "        if high_rating_str in x.review_text.lower():\n",
    "            return POSITIVE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# We can also run [TextBlob](https://textblob.readthedocs.io/en/dev/index.html), a tool that provides a pretrained sentiment analyzer, on the reviews, and use its polarity and subjectivity scores to estimate the user's rating for the book.\n",
    "# As usual, these thresholds were picked by analyzing the score distributions and running error analysis.\n",
    "\n",
    "# %%\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_polarity(x):\n",
    "    if isinstance(x.review_text, str):\n",
    "        x.blob = TextBlob(x.review_text)\n",
    "    else:\n",
    "        x.blob = None\n",
    "    return x\n",
    "\n",
    "\n",
    "# Label high polarity reviews as positive.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_positive(x):\n",
    "    if x.blob:\n",
    "        if x.blob.polarity > 0.3:\n",
    "            return POSITIVE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# Label high subjectivity reviews as positive.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def subjectivity_positive(x):\n",
    "    if x.blob:\n",
    "        if x.blob.subjectivity > 0.75:\n",
    "            return POSITIVE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# Label low polarity reviews as negative.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_negative(x):\n",
    "    if x.blob:\n",
    "        if x.blob.polarity < 0.0:\n",
    "            return NEGATIVE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "from snorkel.labeling import PandasLFApplier, LFAnalysis\n",
    "\n",
    "lfs = [\n",
    "    stars_in_review,\n",
    "    shared_first_author,\n",
    "    polarity_positive,\n",
    "    subjectivity_positive,\n",
    "    polarity_negative,\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "#L_dev = applier.apply(df_dev)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_dev = applier.apply(df=df_dev)\n",
    "L_valid = applier.apply(df=df_valid)\n",
    "L_test = applier.apply(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105048, 5), (795517, 5), (9193, 5), (8989, 5), (42028, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train_filtered.shape, L_train.shape, L_dev.shape, L_valid.shape, L_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0831 00:27:12.849548 139997562042176 label_model.py:852] Computing O...\n",
      "I0831 00:27:12.930830 139997562042176 label_model.py:858] Estimating \\mu...\n",
      "I0831 00:27:15.340078 139997562042176 logger.py:79] [0 epochs]: TRAIN:[loss=0.002]\n",
      "I0831 00:27:15.362257 139997562042176 logger.py:79] [20 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.399481 139997562042176 logger.py:79] [40 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.437438 139997562042176 logger.py:79] [60 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.475462 139997562042176 logger.py:79] [80 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.516991 139997562042176 logger.py:79] [100 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.558420 139997562042176 logger.py:79] [120 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.599933 139997562042176 logger.py:79] [140 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.641887 139997562042176 logger.py:79] [160 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.683358 139997562042176 logger.py:79] [180 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.724900 139997562042176 logger.py:79] [200 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.763812 139997562042176 logger.py:79] [220 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.805340 139997562042176 logger.py:79] [240 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.846545 139997562042176 logger.py:79] [260 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.888028 139997562042176 logger.py:79] [280 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.929613 139997562042176 logger.py:79] [300 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:15.971044 139997562042176 logger.py:79] [320 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.011037 139997562042176 logger.py:79] [340 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.049182 139997562042176 logger.py:79] [360 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.086132 139997562042176 logger.py:79] [380 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.123215 139997562042176 logger.py:79] [400 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.162298 139997562042176 logger.py:79] [420 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.201214 139997562042176 logger.py:79] [440 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.240172 139997562042176 logger.py:79] [460 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.280265 139997562042176 logger.py:79] [480 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.321089 139997562042176 logger.py:79] [500 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.363071 139997562042176 logger.py:79] [520 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.405109 139997562042176 logger.py:79] [540 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.446865 139997562042176 logger.py:79] [560 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.488169 139997562042176 logger.py:79] [580 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.529086 139997562042176 logger.py:79] [600 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.568902 139997562042176 logger.py:79] [620 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.607742 139997562042176 logger.py:79] [640 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.648687 139997562042176 logger.py:79] [660 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.690096 139997562042176 logger.py:79] [680 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.730115 139997562042176 logger.py:79] [700 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.769878 139997562042176 logger.py:79] [720 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.808545 139997562042176 logger.py:79] [740 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.849657 139997562042176 logger.py:79] [760 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.889258 139997562042176 logger.py:79] [780 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.930903 139997562042176 logger.py:79] [800 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:16.970885 139997562042176 logger.py:79] [820 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.011029 139997562042176 logger.py:79] [840 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.051087 139997562042176 logger.py:79] [860 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.091399 139997562042176 logger.py:79] [880 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.131708 139997562042176 logger.py:79] [900 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.171471 139997562042176 logger.py:79] [920 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.210533 139997562042176 logger.py:79] [940 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.249125 139997562042176 logger.py:79] [960 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.290009 139997562042176 logger.py:79] [980 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.328419 139997562042176 logger.py:79] [1000 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.369785 139997562042176 logger.py:79] [1020 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.412340 139997562042176 logger.py:79] [1040 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.451994 139997562042176 logger.py:79] [1060 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.489525 139997562042176 logger.py:79] [1080 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.530157 139997562042176 logger.py:79] [1100 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.571810 139997562042176 logger.py:79] [1120 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.612124 139997562042176 logger.py:79] [1140 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.650887 139997562042176 logger.py:79] [1160 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.692166 139997562042176 logger.py:79] [1180 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.731552 139997562042176 logger.py:79] [1200 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.771170 139997562042176 logger.py:79] [1220 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.812618 139997562042176 logger.py:79] [1240 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.854000 139997562042176 logger.py:79] [1260 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.892598 139997562042176 logger.py:79] [1280 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.933751 139997562042176 logger.py:79] [1300 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:17.972625 139997562042176 logger.py:79] [1320 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.011962 139997562042176 logger.py:79] [1340 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.049950 139997562042176 logger.py:79] [1360 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.089757 139997562042176 logger.py:79] [1380 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.131382 139997562042176 logger.py:79] [1400 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.172945 139997562042176 logger.py:79] [1420 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.214318 139997562042176 logger.py:79] [1440 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.255001 139997562042176 logger.py:79] [1460 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.295323 139997562042176 logger.py:79] [1480 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.335870 139997562042176 logger.py:79] [1500 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.375832 139997562042176 logger.py:79] [1520 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.415404 139997562042176 logger.py:79] [1540 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.454809 139997562042176 logger.py:79] [1560 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.495916 139997562042176 logger.py:79] [1580 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.537778 139997562042176 logger.py:79] [1600 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.579189 139997562042176 logger.py:79] [1620 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.618788 139997562042176 logger.py:79] [1640 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.658730 139997562042176 logger.py:79] [1660 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.699098 139997562042176 logger.py:79] [1680 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.740676 139997562042176 logger.py:79] [1700 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.781490 139997562042176 logger.py:79] [1720 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.821419 139997562042176 logger.py:79] [1740 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.860327 139997562042176 logger.py:79] [1760 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.898678 139997562042176 logger.py:79] [1780 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.939717 139997562042176 logger.py:79] [1800 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:18.979005 139997562042176 logger.py:79] [1820 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.020517 139997562042176 logger.py:79] [1840 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.060850 139997562042176 logger.py:79] [1860 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.102185 139997562042176 logger.py:79] [1880 epochs]: TRAIN:[loss=0.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0831 00:27:19.143492 139997562042176 logger.py:79] [1900 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.184424 139997562042176 logger.py:79] [1920 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.220679 139997562042176 logger.py:79] [1940 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.259344 139997562042176 logger.py:79] [1960 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.298459 139997562042176 logger.py:79] [1980 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.339373 139997562042176 logger.py:79] [2000 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.378401 139997562042176 logger.py:79] [2020 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.419869 139997562042176 logger.py:79] [2040 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.459338 139997562042176 logger.py:79] [2060 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.498853 139997562042176 logger.py:79] [2080 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.540270 139997562042176 logger.py:79] [2100 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.584067 139997562042176 logger.py:79] [2120 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.624565 139997562042176 logger.py:79] [2140 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.665939 139997562042176 logger.py:79] [2160 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.707749 139997562042176 logger.py:79] [2180 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.748591 139997562042176 logger.py:79] [2200 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.788988 139997562042176 logger.py:79] [2220 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.829300 139997562042176 logger.py:79] [2240 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.874004 139997562042176 logger.py:79] [2260 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.913360 139997562042176 logger.py:79] [2280 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.950793 139997562042176 logger.py:79] [2300 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:19.990494 139997562042176 logger.py:79] [2320 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.036991 139997562042176 logger.py:79] [2340 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.084215 139997562042176 logger.py:79] [2360 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.129576 139997562042176 logger.py:79] [2380 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.173333 139997562042176 logger.py:79] [2400 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.216108 139997562042176 logger.py:79] [2420 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.261291 139997562042176 logger.py:79] [2440 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.304148 139997562042176 logger.py:79] [2460 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.351433 139997562042176 logger.py:79] [2480 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.394454 139997562042176 logger.py:79] [2500 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.439745 139997562042176 logger.py:79] [2520 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.483208 139997562042176 logger.py:79] [2540 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.524196 139997562042176 logger.py:79] [2560 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.569661 139997562042176 logger.py:79] [2580 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.615144 139997562042176 logger.py:79] [2600 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.658699 139997562042176 logger.py:79] [2620 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.700050 139997562042176 logger.py:79] [2640 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.740572 139997562042176 logger.py:79] [2660 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.781985 139997562042176 logger.py:79] [2680 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.821591 139997562042176 logger.py:79] [2700 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.860750 139997562042176 logger.py:79] [2720 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.898184 139997562042176 logger.py:79] [2740 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.937766 139997562042176 logger.py:79] [2760 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:20.978228 139997562042176 logger.py:79] [2780 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.020903 139997562042176 logger.py:79] [2800 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.061376 139997562042176 logger.py:79] [2820 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.096847 139997562042176 logger.py:79] [2840 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.135654 139997562042176 logger.py:79] [2860 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.176965 139997562042176 logger.py:79] [2880 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.217433 139997562042176 logger.py:79] [2900 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.255502 139997562042176 logger.py:79] [2920 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.291958 139997562042176 logger.py:79] [2940 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.330370 139997562042176 logger.py:79] [2960 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.366596 139997562042176 logger.py:79] [2980 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.406889 139997562042176 logger.py:79] [3000 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.443739 139997562042176 logger.py:79] [3020 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.485544 139997562042176 logger.py:79] [3040 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.525908 139997562042176 logger.py:79] [3060 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.567192 139997562042176 logger.py:79] [3080 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.608899 139997562042176 logger.py:79] [3100 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.650757 139997562042176 logger.py:79] [3120 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.692186 139997562042176 logger.py:79] [3140 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.732588 139997562042176 logger.py:79] [3160 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.772884 139997562042176 logger.py:79] [3180 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.814140 139997562042176 logger.py:79] [3200 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.854153 139997562042176 logger.py:79] [3220 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.894999 139997562042176 logger.py:79] [3240 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.938514 139997562042176 logger.py:79] [3260 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:21.980926 139997562042176 logger.py:79] [3280 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.024394 139997562042176 logger.py:79] [3300 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.066345 139997562042176 logger.py:79] [3320 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.107966 139997562042176 logger.py:79] [3340 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.141784 139997562042176 logger.py:79] [3360 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.175153 139997562042176 logger.py:79] [3380 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.213244 139997562042176 logger.py:79] [3400 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.254925 139997562042176 logger.py:79] [3420 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.296734 139997562042176 logger.py:79] [3440 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.337998 139997562042176 logger.py:79] [3460 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.377042 139997562042176 logger.py:79] [3480 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.409455 139997562042176 logger.py:79] [3500 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.448383 139997562042176 logger.py:79] [3520 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.487551 139997562042176 logger.py:79] [3540 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.525003 139997562042176 logger.py:79] [3560 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.564094 139997562042176 logger.py:79] [3580 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.598668 139997562042176 logger.py:79] [3600 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.638804 139997562042176 logger.py:79] [3620 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.679262 139997562042176 logger.py:79] [3640 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.721099 139997562042176 logger.py:79] [3660 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.762859 139997562042176 logger.py:79] [3680 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.802943 139997562042176 logger.py:79] [3700 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.843273 139997562042176 logger.py:79] [3720 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.883774 139997562042176 logger.py:79] [3740 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.923761 139997562042176 logger.py:79] [3760 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:22.963234 139997562042176 logger.py:79] [3780 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.002506 139997562042176 logger.py:79] [3800 epochs]: TRAIN:[loss=0.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0831 00:27:23.043234 139997562042176 logger.py:79] [3820 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.082339 139997562042176 logger.py:79] [3840 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.123916 139997562042176 logger.py:79] [3860 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.164530 139997562042176 logger.py:79] [3880 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.203726 139997562042176 logger.py:79] [3900 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.246664 139997562042176 logger.py:79] [3920 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.286974 139997562042176 logger.py:79] [3940 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.326757 139997562042176 logger.py:79] [3960 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.364389 139997562042176 logger.py:79] [3980 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.403776 139997562042176 logger.py:79] [4000 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.445397 139997562042176 logger.py:79] [4020 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.488989 139997562042176 logger.py:79] [4040 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.530606 139997562042176 logger.py:79] [4060 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.570624 139997562042176 logger.py:79] [4080 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.611007 139997562042176 logger.py:79] [4100 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.652473 139997562042176 logger.py:79] [4120 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.693909 139997562042176 logger.py:79] [4140 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.736508 139997562042176 logger.py:79] [4160 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.777779 139997562042176 logger.py:79] [4180 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.816858 139997562042176 logger.py:79] [4200 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.858788 139997562042176 logger.py:79] [4220 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.900493 139997562042176 logger.py:79] [4240 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.940465 139997562042176 logger.py:79] [4260 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:23.986010 139997562042176 logger.py:79] [4280 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.028794 139997562042176 logger.py:79] [4300 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.070798 139997562042176 logger.py:79] [4320 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.110583 139997562042176 logger.py:79] [4340 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.152955 139997562042176 logger.py:79] [4360 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.194568 139997562042176 logger.py:79] [4380 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.239681 139997562042176 logger.py:79] [4400 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.281502 139997562042176 logger.py:79] [4420 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.324299 139997562042176 logger.py:79] [4440 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.365526 139997562042176 logger.py:79] [4460 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.408365 139997562042176 logger.py:79] [4480 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.449248 139997562042176 logger.py:79] [4500 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.492097 139997562042176 logger.py:79] [4520 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.535238 139997562042176 logger.py:79] [4540 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.578007 139997562042176 logger.py:79] [4560 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.618737 139997562042176 logger.py:79] [4580 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.658579 139997562042176 logger.py:79] [4600 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.701305 139997562042176 logger.py:79] [4620 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.744410 139997562042176 logger.py:79] [4640 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.786807 139997562042176 logger.py:79] [4660 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.829689 139997562042176 logger.py:79] [4680 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.870238 139997562042176 logger.py:79] [4700 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.912549 139997562042176 logger.py:79] [4720 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.953635 139997562042176 logger.py:79] [4740 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:24.995387 139997562042176 logger.py:79] [4760 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.038445 139997562042176 logger.py:79] [4780 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.079094 139997562042176 logger.py:79] [4800 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.120241 139997562042176 logger.py:79] [4820 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.161257 139997562042176 logger.py:79] [4840 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.203051 139997562042176 logger.py:79] [4860 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.244590 139997562042176 logger.py:79] [4880 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.286048 139997562042176 logger.py:79] [4900 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.328488 139997562042176 logger.py:79] [4920 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.368372 139997562042176 logger.py:79] [4940 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.410676 139997562042176 logger.py:79] [4960 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.450136 139997562042176 logger.py:79] [4980 epochs]: TRAIN:[loss=0.000]\n",
      "I0831 00:27:25.492244 139997562042176 label_model.py:915] Finished Training\n",
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|██████████| 105048/105048 [03:17<00:00, 532.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Applying labeling functions to the training set\n",
    "#\n",
    "# We apply the labeling functions to the training set, and then filter out data points unlabeled by any LF to form our final training set.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "# L_train = applier.apply(df_train)\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=5000, seed=123, log_freq=20, lr=0.01)\n",
    "preds_train = label_model.predict(L_train)\n",
    "\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, preds_train_filtered = filter_unlabeled_dataframe(\n",
    "    df_train, preds_train, L_train\n",
    ")\n",
    "df_train_filtered[\"rating\"] = preds_train_filtered\n",
    "L_train_filtered = applier.apply(df_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./Data/rec\"\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# df_train_filtered.review_text = df_train_filtered.review_text.fillna('no text')\n",
    "# df_dev.review_text = df_dev.review_text.fillna('no text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid.review_text = df_valid.review_text.fillna('no text')\n",
    "# df_test.review_text = df_test.review_text.fillna('no text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.transform(df_train_filtered[0:10].book_idxs)\n",
    "vectorizer = CountVectorizer()#ngram_range=(1, 2),max_features=10000)\n",
    "# vectorizer = DictVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.book_idxs)\n",
    "X_dev = vectorizer.transform(df_dev.book_idxs).toarray()\n",
    "X_valid = vectorizer.transform(df_valid.book_idxs.tolist())\n",
    "X_test = vectorizer.transform(df_test.book_idxs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============ our changes ==================#\n",
    "def lsnork_to_l_m(lsnork, num_classes):\n",
    "\tm = 1 - np.equal(lsnork,-1).astype(int)\n",
    "\tl = m*lsnork + (1-m)*num_classes\n",
    "\treturn l,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    t = df.book_idxs.values\n",
    "    u = 200#[len(i) for i in t]\n",
    "    v = [np.pad(i,(0,u-len(i)),'constant') for i in t]\n",
    "    return np.asarray(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_x = get_features(df_dev)\n",
    "# d_x = df_dev.book_idxs.values#.toarray()\n",
    "d_L = df_dev.rating.values\n",
    "d_l = L_dev\n",
    "\n",
    "d_l, d_m = lsnork_to_l_m(d_l,2)\n",
    "d_d = np.array([1.0] * len(d_x))\n",
    "d_r = np.zeros(d_l.shape) #rule exemplar coupling unavailable\n",
    "\n",
    "\n",
    "with open(path+\"/\"+\"d_processed.p\",\"wb\") as f:\n",
    "    pickle.dump(d_x,f)\n",
    "    pickle.dump(d_l,f)\n",
    "    pickle.dump(d_m,f)\n",
    "    pickle.dump(d_L,f)\n",
    "    pickle.dump(d_d,f)\n",
    "    pickle.dump(d_r,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U_x = X_train.toarray()\n",
    "U_x = get_features(df_train_filtered)# toarray()\n",
    "U_L = df_train_filtered.rating.values\n",
    "U_l = L_train_filtered\n",
    "U_l, U_m = lsnork_to_l_m(U_l,2)\n",
    "U_d = np.array([0.0] * len(U_x))\n",
    "U_r = np.zeros(U_l.shape)\n",
    "\n",
    "with open(path+\"/\"+\"U_processed.p\",\"wb\") as f:\n",
    "    pickle.dump(U_x,f)\n",
    "    pickle.dump(U_l,f)\n",
    "    pickle.dump(U_m,f)\n",
    "    pickle.dump(U_L,f)\n",
    "    pickle.dump(U_d,f)\n",
    "    pickle.dump(U_r,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_x = get_features(df_valid)\n",
    "valid_L = df_valid.rating.values\n",
    "valid_l = L_valid\n",
    "valid_l, valid_m = lsnork_to_l_m(valid_l,2)\n",
    "valid_d = np.array([0.0] * len(valid_x))\n",
    "valid_r = np.zeros(valid_l.shape) #rule exemplar coupling unavailable\n",
    "with open(path+\"/\"+\"validation_processed.p\",\"wb\") as f:\n",
    "\tpickle.dump(valid_x,f)\n",
    "\tpickle.dump(valid_l,f)\n",
    "\tpickle.dump(valid_m,f)\n",
    "\tpickle.dump(valid_L,f)\n",
    "\tpickle.dump(valid_d,f)\n",
    "\tpickle.dump(valid_r,f)\n",
    "\n",
    "\n",
    "test_x = get_features(df_test)\n",
    "test_L = df_test.rating.values\n",
    "test_l = L_test\n",
    "test_l, test_m = lsnork_to_l_m(test_l,2)\n",
    "test_d = np.array([0.0] * len(test_x))\n",
    "test_r = np.zeros(test_l.shape) #rule exemplar coupling unavailable\n",
    "with open(path+\"/\"+\"test_processed.p\",\"wb\") as f:\n",
    "\tpickle.dump(test_x,f)\n",
    "\tpickle.dump(test_l,f)\n",
    "\tpickle.dump(test_m,f)\n",
    "\tpickle.dump(test_L,f)\n",
    "\tpickle.dump(test_d,f)\n",
    "\tpickle.dump(test_r,f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stars_in_review</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.017264</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>124</td>\n",
       "      <td>23</td>\n",
       "      <td>0.843537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_first_author</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.061186</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>339</td>\n",
       "      <td>182</td>\n",
       "      <td>0.650672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_positive</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.037581</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>244</td>\n",
       "      <td>76</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity_positive</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>93</td>\n",
       "      <td>39</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_negative</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.016207</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>80</td>\n",
       "      <td>58</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "stars_in_review        0   [0, 1]  0.017264  0.004345   0.001409      124   \n",
       "shared_first_author    1      [1]  0.061186  0.001292   0.000000      339   \n",
       "polarity_positive      2      [1]  0.037581  0.012096   0.001057      244   \n",
       "subjectivity_positive  3      [1]  0.015502  0.011274   0.003171       93   \n",
       "polarity_negative      4      [0]  0.016207  0.004110   0.003288       80   \n",
       "\n",
       "                       Incorrect  Emp. Acc.  \n",
       "stars_in_review               23   0.843537  \n",
       "shared_first_author          182   0.650672  \n",
       "polarity_positive             76   0.762500  \n",
       "subjectivity_positive         39   0.704545  \n",
       "polarity_negative             58   0.579710  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L_dev, lfs).lf_summary(df_dev.rating.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ### Applying labeling functions to the training set\n",
    "#\n",
    "# We apply the labeling functions to the training set, and then filter out data points unlabeled by any LF to form our final training set.\n",
    "\n",
    "# %% {\"t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ### Applying labeling functions to the training set\n",
    "#\n",
    "# We apply the labeling functions to the training set, and then filter out data points unlabeled by any LF to form our final training set.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "L_train = applier.apply(df_train)\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=5000, seed=123, log_freq=20, lr=0.01)\n",
    "preds_train = label_model.predict(L_train)\n",
    "\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, preds_train_filtered = filter_unlabeled_dataframe(\n",
    "    df_train, preds_train, L_train\n",
    ")\n",
    "df_train_filtered[\"rating\"] = preds_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1b60e25ff6bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
