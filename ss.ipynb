{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of excludings are  2721\n",
      "Length of U is 1781\n",
      "number of lfs  73\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "from logistic_regression import *\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from cage import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from losses import *\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.set_printoptions(threshold=20)\n",
    "\n",
    "objs = []\n",
    "n_classes = 2# int(sys.argv[11])\n",
    "n_lfs = 73\n",
    "dset_directory = \"Data/SMS\" #sys.argv[10]\n",
    "with open(dset_directory + '/d_processed.p', 'rb') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            o = pickle.load(f)\n",
    "        except EOFError:\n",
    "            break\n",
    "        objs.append(o)\n",
    "\n",
    "x_supervised = torch.tensor(objs[0]).double()\n",
    "y_supervised = torch.tensor(objs[3]).long()\n",
    "l_supervised = torch.tensor(objs[2]).long()\n",
    "s_supervised = torch.tensor(objs[2]).double()\n",
    "\n",
    "objs = []\n",
    "with open(dset_directory + '/U_processed.p', 'rb') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            o = pickle.load(f)\n",
    "        except EOFError:\n",
    "            break\n",
    "        objs.append(o)\n",
    "\n",
    "excl= []\n",
    "idx=0\n",
    "for x in objs[1]:\n",
    "    if(all(x==int(n_classes))):\n",
    "        excl.append(idx)\n",
    "    idx+=1\n",
    "print('no of excludings are ', len(excl))\n",
    "\n",
    "x_unsupervised = torch.tensor(np.delete(objs[0],excl, axis=0)).double()\n",
    "y_unsupervised = torch.tensor(np.delete(objs[3],excl, axis=0)).long()\n",
    "l_unsupervised = torch.tensor(np.delete(objs[2],excl, axis=0)).long()\n",
    "s_unsupervised = torch.tensor(np.delete(objs[2],excl, axis=0)).double()\n",
    "\n",
    "print('Length of U is', len(x_unsupervised))\n",
    "\n",
    "objs = []\n",
    "with open(dset_directory + '/validation_processed.p', 'rb') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            o = pickle.load(f)\n",
    "        except EOFError:\n",
    "            break\n",
    "        objs.append(o)\n",
    "\n",
    "x_valid = torch.tensor(objs[0]).double()\n",
    "y_valid = objs[3]\n",
    "l_valid = torch.tensor(objs[2]).long()\n",
    "s_valid = torch.tensor(objs[2]).double()\n",
    "\n",
    "objs1 = []\n",
    "with open(dset_directory + '/test_processed.p', 'rb') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            o = pickle.load(f)\n",
    "        except EOFError:\n",
    "            break\n",
    "        objs1.append(o)\n",
    "x_test = torch.tensor(objs1[0]).double()\n",
    "y_test = objs1[3]\n",
    "l_test = torch.tensor(objs1[2]).long()\n",
    "s_test = torch.tensor(objs1[2]).double()\n",
    "\n",
    "\n",
    "n_features = x_supervised.shape[1]\n",
    "\n",
    "# Labeling Function Classes\n",
    "# k = torch.from_numpy(np.array([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0])).long()\n",
    "#lf_classes_file = sys.argv[11]\n",
    "k = torch.from_numpy(np.array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])).long()\n",
    "k = 1 - k\n",
    "# k = torch.from_numpy(np.load(dset_directory + '/k.npy'))\n",
    "# n_lfs = int(len(k))\n",
    "print('number of lfs ', n_lfs)\n",
    "\n",
    "continuous_mask = torch.zeros(n_lfs).double()\n",
    "\n",
    "\n",
    "for i in range(s_supervised.shape[0]):\n",
    "    for j in range(s_supervised.shape[1]):\n",
    "        if s_supervised[i, j].item() > 0.999:\n",
    "            s_supervised[i, j] = 0.999\n",
    "        if s_supervised[i, j].item() < 0.001:\n",
    "            s_supervised[i, j] = 0.001\n",
    "\n",
    "for i in range(s_unsupervised.shape[0]):\n",
    "    for j in range(s_unsupervised.shape[1]):\n",
    "        if s_unsupervised[i, j].item() > 0.999:\n",
    "            s_unsupervised[i, j] = 0.999\n",
    "        if s_unsupervised[i, j].item() < 0.001:\n",
    "            s_unsupervised[i, j] = 0.001\n",
    "\n",
    "for i in range(s_valid.shape[0]):\n",
    "    for j in range(s_valid.shape[1]):\n",
    "        if s_valid[i, j].item() > 0.999:\n",
    "            s_valid[i, j] = 0.999\n",
    "        if s_valid[i, j].item() < 0.001:\n",
    "            s_valid[i, j] = 0.001\n",
    "\n",
    "for i in range(s_test.shape[0]):\n",
    "    for j in range(s_test.shape[1]):\n",
    "        if s_test[i, j].item() > 0.999:\n",
    "            s_test[i, j] = 0.999\n",
    "        if s_test[i, j].item() < 0.001:\n",
    "            s_test[i, j] = 0.001\n",
    "\n",
    "\n",
    "\n",
    "l = torch.cat([l_supervised, l_unsupervised])\n",
    "s = torch.cat([s_supervised, s_unsupervised])\n",
    "x_train = torch.cat([x_supervised, x_unsupervised])\n",
    "y_train = torch.cat([y_supervised, y_unsupervised])\n",
    "supervised_mask = torch.cat([torch.ones(l_supervised.shape[0]), torch.zeros(l_unsupervised.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  tensor([0.9000, 0.9000, 0.9000,  ..., 0.9000, 0.9000, 0.9000])\n",
      "torch.Size([69, 73])\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "## Quality Guides ##\n",
    "\n",
    "a = torch.ones(n_lfs).double() * 0.9\n",
    "print('before ',a)\n",
    "prec_lfs=[]\n",
    "for i in range(n_lfs):\n",
    "   correct = 0\n",
    "   for j in range(len(y_valid)):\n",
    "       if y_valid[j] == l_valid[j][i]:\n",
    "           correct+=1\n",
    "   prec_lfs.append(correct/len(y_valid))\n",
    "a = torch.tensor(prec_lfs) \n",
    "## End Quality Quides##\n",
    "# a =  torch.tensor(np.load(dset_directory + '/precision_values.npy'))\n",
    "# print('after ',a)\n",
    "\n",
    "#Setting |validation|=|supevised|\n",
    "x_valid = x_valid[0:len(x_supervised)]\n",
    "y_valid = y_valid[0:len(x_supervised)]\n",
    "s_valid = s_valid[0:len(x_supervised)]\n",
    "l_valid = l_valid[0:len(x_supervised)]\n",
    "\n",
    "print(l_valid.shape)\n",
    "print(l_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8986, 0.8986, 0.8986,  ..., 0.8986, 0.8986, 0.8986])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[50:73] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num runs are  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/ipykernel_launcher.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/ipykernel_launcher.py:107: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/ipykernel_launcher.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ayusham/.conda/envs/poincare/lib/python3.6/site-packages/ipykernel_launcher.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t Test GM accuracy_score: 0.17647058823529413\n",
      "Epoch: 0\tGM accuracy_score(Valid): 0.36363636363636365\n",
      "Epoch: 0\tTest LR accuracy_score: 0.7727272727272727\n",
      "Epoch: 0\tLR accuracy_score(Valid): 0.7272727272727273\n",
      "Epoch: 1\t Test GM accuracy_score: 0.19999999999999998\n",
      "Epoch: 1\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 1\tTest LR accuracy_score: 0.7387387387387387\n",
      "Epoch: 1\tLR accuracy_score(Valid): 0.923076923076923\n",
      "Epoch: 2\t Test GM accuracy_score: 0.19999999999999998\n",
      "Epoch: 2\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 2\tTest LR accuracy_score: 0.8541666666666667\n",
      "Epoch: 2\tLR accuracy_score(Valid): 0.923076923076923\n",
      "Epoch: 3\t Test GM accuracy_score: 0.19999999999999998\n",
      "Epoch: 3\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 3\tTest LR accuracy_score: 0.8888888888888888\n",
      "Epoch: 3\tLR accuracy_score(Valid): 1.0\n",
      "Epoch: 4\t Test GM accuracy_score: 0.19999999999999998\n",
      "Epoch: 4\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 4\tTest LR accuracy_score: 0.8775510204081632\n",
      "Epoch: 4\tLR accuracy_score(Valid): 1.0\n",
      "Epoch: 5\t Test GM accuracy_score: 0.19999999999999998\n",
      "Epoch: 5\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 5\tTest LR accuracy_score: 0.8\n",
      "Epoch: 5\tLR accuracy_score(Valid): 0.923076923076923\n",
      "Epoch: 6\t Test GM accuracy_score: 0.25\n",
      "Epoch: 6\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 6\tTest LR accuracy_score: 0.56\n",
      "Epoch: 6\tLR accuracy_score(Valid): 0.6\n",
      "Epoch: 7\t Test GM accuracy_score: 0.25\n",
      "Epoch: 7\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 7\tTest LR accuracy_score: 0.6153846153846153\n",
      "Epoch: 7\tLR accuracy_score(Valid): 0.6\n",
      "Epoch: 8\t Test GM accuracy_score: 0.25\n",
      "Epoch: 8\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 8\tTest LR accuracy_score: 0.8800000000000001\n",
      "Epoch: 8\tLR accuracy_score(Valid): 1.0\n",
      "Epoch: 9\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 9\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 9\tTest LR accuracy_score: 0.7777777777777778\n",
      "Epoch: 9\tLR accuracy_score(Valid): 0.923076923076923\n",
      "Epoch: 10\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 10\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 10\tTest LR accuracy_score: 0.7499999999999999\n",
      "Epoch: 10\tLR accuracy_score(Valid): 0.7272727272727273\n",
      "Epoch: 11\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 11\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 11\tTest LR accuracy_score: 0.8172043010752689\n",
      "Epoch: 11\tLR accuracy_score(Valid): 1.0\n",
      "Epoch: 12\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 12\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 12\tTest LR accuracy_score: 0.6904761904761905\n",
      "Epoch: 12\tLR accuracy_score(Valid): 0.6\n",
      "Epoch: 13\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 13\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 13\tTest LR accuracy_score: 0.7912087912087912\n",
      "Epoch: 13\tLR accuracy_score(Valid): 0.923076923076923\n",
      "Epoch: 14\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 14\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 14\tTest LR accuracy_score: 0.7586206896551725\n",
      "Epoch: 14\tLR accuracy_score(Valid): 0.7272727272727273\n",
      "Epoch: 15\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 15\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 15\tTest LR accuracy_score: 0.6904761904761905\n",
      "Epoch: 15\tLR accuracy_score(Valid): 0.6\n",
      "Epoch: 16\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 16\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 16\tTest LR accuracy_score: 0.625\n",
      "Epoch: 16\tLR accuracy_score(Valid): 0.6\n",
      "Epoch: 17\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 17\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 17\tTest LR accuracy_score: 0.5591397849462365\n",
      "Epoch: 17\tLR accuracy_score(Valid): 0.6\n",
      "Epoch: 18\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 18\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 18\tTest LR accuracy_score: 0.7741935483870968\n",
      "Epoch: 18\tLR accuracy_score(Valid): 0.923076923076923\n",
      "Epoch: 19\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 19\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 19\tTest LR accuracy_score: 0.7640449438202247\n",
      "Epoch: 19\tLR accuracy_score(Valid): 0.8333333333333333\n",
      "Epoch: 20\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 20\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 20\tTest LR accuracy_score: 0.6796116504854369\n",
      "Epoch: 20\tLR accuracy_score(Valid): 0.7692307692307692\n",
      "Epoch: 21\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 21\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 21\tTest LR accuracy_score: 0.7708333333333335\n",
      "Epoch: 21\tLR accuracy_score(Valid): 0.8333333333333333\n",
      "Epoch: 22\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 22\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 22\tTest LR accuracy_score: 0.7356321839080459\n",
      "Epoch: 22\tLR accuracy_score(Valid): 0.7272727272727273\n",
      "Epoch: 23\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 23\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 23\tTest LR accuracy_score: 0.7777777777777778\n",
      "Epoch: 23\tLR accuracy_score(Valid): 0.8333333333333333\n",
      "Epoch: 24\t Test GM accuracy_score: 0.273972602739726\n",
      "Epoch: 24\tGM accuracy_score(Valid): 0.5\n",
      "Epoch: 24\tTest LR accuracy_score: 0.5897435897435898\n",
      "Epoch: 24\tLR accuracy_score(Valid): 0.6\n"
     ]
    }
   ],
   "source": [
    "num_runs = 1 #int(sys.argv[9])\n",
    "# l1, l2,l3,l4,l5,l6,qg=True,True, False, False, False,False, False #L12\n",
    "l1, l2,l3,l4,l5,l6,qg=True,True, True,True, True,True, True # L123456qg\n",
    "# l1, l2,l3,l4,l5,l6,qg=True,True, True, True, True,True, True#L12346qg\n",
    "# l1, l2,l3,l4,l5,l6,qg=False,False, False, False, True,False, True#L5qg\n",
    "final_score_gm, final_score_lr, final_score_gm_val, final_score_lr_val = [],[],[],[]\n",
    "for lo in range(0,num_runs):\n",
    "    pi = torch.ones(n_classes, n_lfs).double()\n",
    "    pi.requires_grad = True\n",
    "\n",
    "    theta = torch.ones((n_classes, n_lfs)).double() * 1\n",
    "    theta.requires_grad = True\n",
    "\n",
    "    pi_y = torch.ones(n_classes).double()\n",
    "    pi_y.requires_grad = True\n",
    "\n",
    "    lr_model = LogisticRegression(n_features, n_classes)\n",
    "\n",
    "    optimizer = torch.optim.Adam([{\"params\": lr_model.parameters()}, {\"params\": [pi, pi_y, theta]}], lr=0.003)\n",
    "    optimizer_lr = torch.optim.Adam(lr_model.parameters(), lr=0.003)\n",
    "    optimizer_gm = torch.optim.Adam([theta, pi, pi_y], lr=0.01, weight_decay=0)\n",
    "    # optimizer = torch.optim.Adam([theta, pi, pi_y], lr=0.01, weight_decay=0)\n",
    "    supervised_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "    dataset = TensorDataset(x_train, y_train, l, s, supervised_mask)\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True,pin_memory=True)\n",
    "#     save_folder = sys.argv[1]\n",
    "    print('num runs are ', num_runs)\n",
    "    best_score_lr,best_score_gm,best_epoch_lr,best_epoch_gm,best_score_lr_val, best_score_gm_val = 0,0,0,0,0,0\n",
    "    stop_pahle, stop_pahle_gm = [], []\n",
    "\n",
    "    for epoch in range(25):\n",
    "        lr_model.train()\n",
    "\n",
    "        for batch_ndx, sample in enumerate(loader):\n",
    "            optimizer_lr.zero_grad()\n",
    "            optimizer_gm.zero_grad()\n",
    "\n",
    "            \n",
    "\n",
    "            # Start entropy code\n",
    "            # unsupervised_indices = (1-sample[4]).nonzero().squeeze()\n",
    "            unsup = []\n",
    "            sup = []\n",
    "            # probs_graphical = probability(theta, pi_y, pi, sample[2][unsupervised_indices], \\\n",
    "            #     sample[3][unsupervised_indices], k, n_classes, continuous_mask)\n",
    "            # probs_graphical = (probs_graphical.t() / probs_graphical.sum(1)).t()\n",
    "\n",
    "            # ent = entropy_pre(probs_graphical)\n",
    "\n",
    "            # sorts, indices  = torch.sort(ent)\n",
    "            # indices = indices.tolist()\n",
    "            # indices = indices[:int(len(indices)/2)]\n",
    "            ## Finsished - entropy code\n",
    "\n",
    "            # l = torch.cat([l_supervised, l_unsupervised[indices]])\n",
    "            # s = torch.cat([s_supervised, s_unsupervised[indices]])\n",
    "            # x_train = torch.cat([x_supervised, x_unsupervised[indices]])\n",
    "            # y_train = torch.cat([y_supervised, y_unsupervised[indices]])\n",
    "            # supervised_mask = torch.cat([torch.ones(l_supervised.shape[0]), torch.zeros(l_unsupervised[indices].shape[0])])\n",
    "\n",
    "            supervised_indices = sample[4].nonzero().view(-1)\n",
    "            # unsupervised_indices = indices  ## Uncomment for entropy\n",
    "            unsupervised_indices = (1-sample[4]).nonzero().squeeze()\n",
    "\n",
    "\n",
    "            if(l1):\n",
    "                if len(supervised_indices) > 0:\n",
    "                    loss_1 = supervised_criterion(lr_model(sample[0][supervised_indices]), sample[1][supervised_indices])\n",
    "                else:\n",
    "                    loss_1 = 0\n",
    "            else:\n",
    "                loss_1=0\n",
    "\n",
    "            if(l2):\n",
    "                unsupervised_lr_probability = torch.nn.Softmax()(lr_model(sample[0][unsupervised_indices]))\n",
    "                loss_2 = entropy(unsupervised_lr_probability)\n",
    "            else:\n",
    "                loss_2=0\n",
    "            if(l3):\n",
    "                y_pred_unsupervised = np.argmax(probability(theta, pi_y, pi, sample[2][unsupervised_indices], sample[3][unsupervised_indices], k, n_classes,continuous_mask).detach().numpy(), 1)\n",
    "                loss_3 = supervised_criterion(lr_model(sample[0][unsupervised_indices]), torch.tensor(y_pred_unsupervised))\n",
    "            else:\n",
    "                loss_3 = 0\n",
    "\n",
    "            if (l4 and len(supervised_indices) > 0):\n",
    "                loss_4 = log_likelihood_loss_supervised(theta, pi_y, pi, sample[1][supervised_indices], sample[2][supervised_indices], sample[3][supervised_indices], k, n_classes,\n",
    "                                                        continuous_mask)\n",
    "            else:\n",
    "                loss_4 = 0\n",
    "\n",
    "            if(l5):\n",
    "                loss_5 = log_likelihood_loss(theta, pi_y, pi, sample[2][unsupervised_indices], sample[3][unsupervised_indices], k, n_classes, continuous_mask)\n",
    "            else:\n",
    "                loss_5 =0\n",
    "\n",
    "            if(l6):\n",
    "                if(len(supervised_indices) >0):\n",
    "                    supervised_indices = supervised_indices.tolist()\n",
    "                    probs_graphical = probability(theta, pi_y, pi, torch.cat([sample[2][unsupervised_indices], sample[2][supervised_indices]]),\\\n",
    "                    torch.cat([sample[3][unsupervised_indices],sample[3][supervised_indices]]), k, n_classes, continuous_mask)\n",
    "                else:\n",
    "                    probs_graphical = probability(theta, pi_y, pi,sample[2][unsupervised_indices],sample[3][unsupervised_indices],\\\n",
    "                         k, n_classes, continuous_mask)\n",
    "                probs_graphical = (probs_graphical.t() / probs_graphical.sum(1)).t()\n",
    "                probs_lr = torch.nn.Softmax()(lr_model(sample[0]))\n",
    "                loss_6 = kl_divergence(probs_graphical, probs_lr)\n",
    "\n",
    "            else:\n",
    "                loss_6= 0\n",
    "            # loss_6 = - torch.log(1 - probs_graphical * (1 - probs_lr)).sum(1).mean()\n",
    "            if(qg):\n",
    "                prec_loss = precision_loss(theta, k, n_classes, a)\n",
    "            else:\n",
    "                prec_loss =0\n",
    "\n",
    "            loss = loss_1 + loss_2 + loss_3 + loss_4 + loss_6+loss_5 + 5*prec_loss\n",
    "            # print('loss is',loss)\n",
    "            if loss != 0:\n",
    "                loss.backward()\n",
    "                optimizer_gm.step()\n",
    "                optimizer_lr.step()\n",
    "\n",
    "        #print(lr_model.state_dict())\n",
    "        #print(theta,pi)\n",
    "        #Test\n",
    "        y_pred = np.argmax(probability(theta, pi_y, pi, l_test, s_test, k, n_classes, continuous_mask).detach().numpy(), 1)\n",
    "        gm_acc = f1_score(y_test, y_pred)\n",
    "        #Valid\n",
    "        y_pred = np.argmax(probability(theta, pi_y, pi, l_valid, s_valid, k, n_classes, continuous_mask).detach().numpy(), 1)\n",
    "        gm_valid_acc = f1_score(y_valid, y_pred)\n",
    "        # print(y_valid, y_pred)\n",
    "\n",
    "        #LR Test\n",
    "\n",
    "        probs = torch.nn.Softmax()(lr_model(x_test))\n",
    "        y_pred = np.argmax(probs.detach().numpy(), 1)\n",
    "        lr_acc =f1_score(y_test, y_pred)\n",
    "        #LR Valid\n",
    "        probs = torch.nn.Softmax()(lr_model(x_valid))\n",
    "        y_pred = np.argmax(probs.detach().numpy(), 1)\n",
    "        lr_valid_acc = f1_score(y_valid, y_pred)\n",
    "\n",
    "        print(\"Epoch: {}\\t Test GM accuracy_score: {}\".format(epoch, gm_acc ))\n",
    "        print(\"Epoch: {}\\tGM accuracy_score(Valid): {}\".format(epoch, gm_valid_acc))\n",
    "        print(\"Epoch: {}\\tTest LR accuracy_score: {}\".format(epoch, lr_acc ))    \n",
    "        print(\"Epoch: {}\\tLR accuracy_score(Valid): {}\".format(epoch, lr_valid_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([73])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f78b3c5ff60>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(range(len(theta[0])), theta[0].detach().numpy(), label=\"theta[0]\")\n",
    "plt.scatter(range(len(theta[1])), theta[1].detach().numpy(), label=\"theta[1]\")\n",
    "plt.scatter(range(len(pi[0])), pi[0].detach().numpy(), label=\"pi[0]\")\n",
    "plt.scatter(range(len(pi[1])), pi[1].detach().numpy(), label=\"pi[1]\")\n",
    "plt.xlabel('LFs')\n",
    "plt.ylabel('Weights of LFs')\n",
    "plt.title('SMS -> l5qg+None=0')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('np.txt', theta.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if gm_valid_acc > best_score_gm_val and gm_valid_acc > best_score_lr_val:\n",
    "            # print(\"Inside Best hu Epoch: {}\\t Test GM accuracy_score: {}\".format(epoch, gm_acc ))\n",
    "            # print(\"Inside Best hu Epoch: {}\\tGM accuracy_score(Valid): {}\".format(epoch, gm_valid_acc))\n",
    "            best_epoch_gm = epoch\n",
    "            best_score_gm_val = gm_valid_acc\n",
    "            best_score_gm = gm_acc\n",
    "            best_epoch_lr = epoch\n",
    "            best_score_lr_val = lr_valid_acc\n",
    "            best_score_lr = lr_acc\n",
    "            checkpoint = {'theta': theta,'pi': pi}\n",
    "            torch.save(checkpoint, save_folder+\"/gm_\"+str(epoch)    +\".pt\")\n",
    "            checkpoint = {'params': lr_model.state_dict()}\n",
    "            torch.save(checkpoint, save_folder+\"/lr_\"+ str(epoch)+\".pt\")\n",
    "            stop_pahle = []\n",
    "            stop_pahle_gm = []\n",
    "\n",
    "        if lr_valid_acc > best_score_lr_val and lr_valid_acc > best_score_gm_val:\n",
    "            # print(\"Inside Best hu Epoch: {}\\tTest LR accuracy_score: {}\".format(epoch, lr_acc ))\n",
    "            # print(\"Inside Best hu Epoch: {}\\tLR accuracy_score(Valid): {}\".format(epoch, lr_valid_acc))\n",
    "            best_epoch_lr = epoch\n",
    "            best_score_lr_val = lr_valid_acc\n",
    "            best_score_lr = lr_acc\n",
    "            best_epoch_gm = epoch\n",
    "            best_score_gm_val = gm_valid_acc\n",
    "            best_score_gm = gm_acc\n",
    "            checkpoint = {'theta': theta,'pi': pi}\n",
    "            torch.save(checkpoint, save_folder+\"/gm_\"+str(epoch)    +\".pt\")\n",
    "            checkpoint = {'params': lr_model.state_dict()}\n",
    "            torch.save(checkpoint, save_folder+\"/lr_\"+ str(epoch)+\".pt\")\n",
    "            stop_pahle = []\n",
    "            stop_pahle_gm = []\n",
    "\n",
    "\n",
    "        if len(stop_pahle) >100 and len(stop_pahle_gm) >100 and (all(best_score_lr_val >= k for k in stop_pahle) or \\\n",
    "        all(best_score_gm_val >= k for k in stop_pahle_gm)):\n",
    "            print('Early Stopping at', best_epoch_gm, best_score_gm, best_score_lr)\n",
    "            print('Validation score Early Stopping at', best_epoch_gm, best_score_lr_val, best_score_gm_val)\n",
    "            break\n",
    "        else:\n",
    "            # print('inside else stop pahle epoch', epoch)\n",
    "            stop_pahle.append(lr_valid_acc)\n",
    "            stop_pahle_gm.append(gm_valid_acc)\n",
    "\n",
    "    # print(\"Run \\t\",lo, \"Epoch Gm, Epoch LR, GM, LR \\t\", best_epoch_gm, best_epoch_lr,best_score_gm, best_score_lr)\n",
    "    # print(\"Run \\t\",lo, \"GM Val, LR Val \\t\", best_score_gm_val, best_score_lr_val)\n",
    "    print(\"Run \\t\",lo, \"Epoch, GM, LR \\t\",best_epoch_lr, best_score_gm, best_score_lr)\n",
    "    print(\"Run \\t\",lo, \"GM Val, LR Val \\t\", epoch, best_score_gm_val, best_score_lr_val)\n",
    "    final_score_gm.append(best_score_gm)\n",
    "    final_score_lr.append(best_score_lr)\n",
    "    final_score_gm_val.append(best_score_gm_val)\n",
    "    final_score_lr_val.append(best_score_lr_val)\n",
    "\n",
    "\n",
    "print(\"Averaged scores are for GM,LR\", np.sum(final_score_gm)/num_runs, np.sum(final_score_lr)/num_runs)\n",
    "print(\"VALIDATION Averaged scores are for GM,LR\", np.sum(final_score_gm_val)/num_runs, np.sum(final_score_lr_val)/num_runs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
